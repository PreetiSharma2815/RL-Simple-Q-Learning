{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4    5\n",
       "0 -1 -1 -1 -1  0   -1\n",
       "1 -1 -1 -1  0 -1  100\n",
       "2 -1 -1 -1  0 -1   -1\n",
       "3 -1  0  0 -1  0   -1\n",
       "4  0 -1 -1  0 -1  100\n",
       "5 -1  0 -1 -1  0  100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = np.array([\n",
    "    [-1, -1, -1, -1,  0,  -1],\n",
    "    [-1, -1, -1,  0, -1, 100],\n",
    "    [-1, -1, -1 , 0 ,-1 , -1],\n",
    "    [-1,  0,  0 ,-1  ,0 , -1],\n",
    "    [0, -1, -1 , 0 ,-1 ,100],\n",
    "    [-1,  0, -1, -1,  0, 100] \n",
    "])\n",
    "pd.DataFrame(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1  0 -1 -1]\n",
      "(0, -1)\n",
      "(1, -1)\n",
      "(2, -1)\n",
      "(3, 0)\n",
      "(4, -1)\n",
      "(5, -1)\n"
     ]
    }
   ],
   "source": [
    "print(rewards[2])\n",
    "for i in enumerate(rewards[2]):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_state():\n",
    "    return np.random.randint(0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_initial_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(current_state, reward_matrix):\n",
    "    available_action = []\n",
    "    print(\"reward_matrix\",\"\\n\",reward_matrix)    \n",
    "    for action in enumerate(reward_matrix[current_state]):     \n",
    "        if action[1]!= -1:            \n",
    "            available_action.append(action[0]) \n",
    "    print(\"Random choice of action from\",available_action,\"is\", random.choice(available_action))           \n",
    "    return random.choice(available_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "q_matrix = np.zeros([6,6])\n",
    "print(q_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_action(current_state, reward_matrix, gamma):\n",
    "    \n",
    "    action = get_action(current_state, reward_matrix)\n",
    "    \n",
    "    #Current State, Action Reward\n",
    "    current_sa_reward = reward_matrix[current_state, action]\n",
    "    \n",
    "    # New State, Action Reward\n",
    "    q_sa_value = max(q_matrix[action,])\n",
    "\n",
    "    # Current Q state\n",
    "    q_current_state = current_sa_reward + (gamma * q_sa_value)\n",
    "\n",
    "    # Update Q matrix\n",
    "    q_matrix[current_state,action] = q_current_state\n",
    "\n",
    "    new_state = action\n",
    "    print(\"q_matrix \",\"\\n\",q_matrix)\n",
    "    print(\"********************************************************************\")\n",
    "    if new_state == 5:\n",
    "        print(\"Reached Goal!\")\n",
    "    else: \n",
    "        print(f\"Old State:{current_state} New State: {new_state}\")\n",
    "        \n",
    "    return new_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(initial_state,reward_matrix, gamma): \n",
    "    new_state =  take_action(initial_state, reward_matrix, gamma)\n",
    "    while True:\n",
    "        if new_state == 5:\n",
    "            break\n",
    "        else:\n",
    "            new_state =  take_action(new_state, reward_matrix, gamma)            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(episodes, reward_matrix, gamma):\n",
    "    print(\"Training...\")\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        print(\"Starting Episode\")\n",
    "\n",
    "        # Set initial State\n",
    "        initial_state = set_initial_state()\n",
    "        print(\"Initial State:\", initial_state)\n",
    "\n",
    "        # Initalise Episode(Get Action, Take Action to get new state)\n",
    "        run_episode(initial_state, reward_matrix, gamma)\n",
    "\n",
    "        print(\"Ending Episode\")\n",
    "\n",
    "    print(\"Training completed!\")\n",
    "    \n",
    "    return q_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Starting Episode\n",
      "Initial State: 2\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [3] is 3\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:2 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 1\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 4\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [0, 3, 5] is 5\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:4 New State: 0\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [4] is 4\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:0 New State: 4\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [0, 3, 5] is 3\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:4 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 4\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 1\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [3, 5] is 5\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:1 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 2\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 4\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [0, 3, 5] is 3\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:4 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 4\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 2\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [3] is 3\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:2 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 1\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 4\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [0, 3, 5] is 5\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:4 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 1\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 4\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [0, 3, 5] is 5\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:4 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 2\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 2\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [3] is 3\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:2 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 2\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 2\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [3] is 3\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:2 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 4\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 4\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [0, 3, 5] is 3\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:4 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 1\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 4\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [0, 3, 5] is 5\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:4 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 2\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 2\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [3] is 3\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:2 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 4\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 2\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [3] is 3\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:2 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 1\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 2\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [3] is 3\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:2 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 4\n",
      "q_matrix  \n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 1\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [3, 5] is 5\n",
      "q_matrix  \n",
      " [[  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0. 100.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]]\n",
      "********************************************************************\n",
      "Reached Goal!\n",
      "Ending Episode\n",
      "Starting Episode\n",
      "Initial State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 1\n",
      "q_matrix  \n",
      " [[  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0. 100.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 2\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [3] is 3\n",
      "q_matrix  \n",
      " [[  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0. 100.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]]\n",
      "********************************************************************\n",
      "Old State:2 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 1\n",
      "q_matrix  \n",
      " [[  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0. 100.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 4\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [0, 3, 5] is 0\n",
      "q_matrix  \n",
      " [[  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0. 100.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]]\n",
      "********************************************************************\n",
      "Old State:4 New State: 0\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [4] is 4\n",
      "q_matrix  \n",
      " [[  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0. 100.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]]\n",
      "********************************************************************\n",
      "Old State:0 New State: 4\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [0, 3, 5] is 5\n",
      "q_matrix  \n",
      " [[  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0. 100.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]]\n",
      "********************************************************************\n",
      "Old State:4 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 2\n",
      "q_matrix  \n",
      " [[  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0. 100.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 2\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [3] is 3\n",
      "q_matrix  \n",
      " [[  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0. 100.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]]\n",
      "********************************************************************\n",
      "Old State:2 New State: 3\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [1, 2, 4] is 1\n",
      "q_matrix  \n",
      " [[  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0. 100.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.  80.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]]\n",
      "********************************************************************\n",
      "Old State:3 New State: 1\n",
      "reward_matrix \n",
      " [[ -1  -1  -1  -1   0  -1]\n",
      " [ -1  -1  -1   0  -1 100]\n",
      " [ -1  -1  -1   0  -1  -1]\n",
      " [ -1   0   0  -1   0  -1]\n",
      " [  0  -1  -1   0  -1 100]\n",
      " [ -1   0  -1  -1   0 100]]\n",
      "Random choice of action from [3, 5] is 3\n",
      "q_matrix  \n",
      " [[  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0. 100.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.  80.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]]\n",
      "********************************************************************\n",
      "Reached Goal!\n",
      "Ending Episode\n",
      "Training completed!\n",
      "Final Q Table:  [[  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0. 100.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.  80.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.8\n",
    "\n",
    "# Get Q table\n",
    "q_table = train(2, rewards, gamma)\n",
    "\n",
    "print(\"Final Q Table: \", q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_reward(q_table):\n",
    "    max_reward = max(q_table[q_table.nonzero()])\n",
    "    return max_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_path(q_table):\n",
    "    path=[]\n",
    "    path_index = q_table.nonzero()\n",
    "    for i in path_index:\n",
    "        path.append(i[0])\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5]\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "Q_optimal_path = optimal_path(q_table)\n",
    "max_reward = get_max_reward(q_table)\n",
    "print(Q_optimal_path)\n",
    "print(max_reward)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ccbab8b71781e4a1a095404f4bb33e427fbef117b48537af43f7136315609efe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('open_gym_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
